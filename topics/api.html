<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml" lang="zh_CN">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>核心API &#8212; Scrapy 0.24.1 文档</title>
    
    <link rel="stylesheet" href="../static/scrapydoc.css" type="text/css" />
    <link rel="stylesheet" href="../static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../',
        VERSION:     '0.24.1',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="../static/jquery.js"></script>
    <script type="text/javascript" src="../static/underscore.js"></script>
    <script type="text/javascript" src="../static/doctools.js"></script>
    <script type="text/javascript" src="../static/translations.js"></script>
    <link rel="top" title="Scrapy 0.24.1 文档" href="../index.html" />
    <link rel="next" title="Requests and Responses" href="request-response.html" />
    <link rel="prev" title="扩展(Extensions)" href="extensions.html" />
   
  <link rel="stylesheet" href="../static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head>
  <body role="document">
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
    
  <div class="section" id="api">
<span id="topics-api"></span><h1>核心API<a class="headerlink" href="#api" title="永久链接至标题">¶</a></h1>
<div class="versionadded">
<p><span class="versionmodified">0.15 新版功能.</span></p>
</div>
<p>该节文档讲述Scrapy核心API，目标用户是开发Scrapy扩展(extensions)和中间件(middlewares)的开发人员。</p>
<div class="section" id="crawler-api">
<span id="topics-api-crawler"></span><h2>Crawler API<a class="headerlink" href="#crawler-api" title="永久链接至标题">¶</a></h2>
<p>Scrapy API的主要入口是 <a class="reference internal" href="#scrapy.crawler.Crawler" title="scrapy.crawler.Crawler"><code class="xref py py-class docutils literal"><span class="pre">Crawler</span></code></a> 的实例对象，
通过类方法 <code class="docutils literal"><span class="pre">from_crawler</span></code> 将它传递给扩展(extensions)。
该对象提供对所有Scrapy核心组件的访问，
也是扩展访问Scrapy核心组件和挂载功能到Scrapy的唯一途径。</p>
<span class="target" id="module-scrapy.crawler"></span><p>Extension Manager负责加载和跟踪已经安装的扩展，
它通过 <a class="reference internal" href="settings.html#std:setting-EXTENSIONS"><code class="xref std std-setting docutils literal"><span class="pre">EXTENSIONS</span></code></a> 配置，包含一个所有可用扩展的字典，
字典的顺序跟你在 <a class="reference internal" href="downloader-middleware.html#topics-downloader-middleware-setting"><span class="std std-ref">configure the downloader middlewares</span></a> 配置的顺序一致。</p>
<dl class="class">
<dt id="scrapy.crawler.Crawler">
<em class="property">class </em><code class="descclassname">scrapy.crawler.</code><code class="descname">Crawler</code><span class="sig-paren">(</span><em>spidercls</em>, <em>settings</em><span class="sig-paren">)</span><a class="headerlink" href="#scrapy.crawler.Crawler" title="永久链接至目标">¶</a></dt>
<dd><p>Crawler必须使用
<a class="reference internal" href="spiders.html#scrapy.spider.Spider" title="scrapy.spider.Spider"><code class="xref py py-class docutils literal"><span class="pre">scrapy.spider.Spider</span></code></a> 子类及
<a class="reference internal" href="#scrapy.settings.Settings" title="scrapy.settings.Settings"><code class="xref py py-class docutils literal"><span class="pre">scrapy.settings.Settings</span></code></a> 的对象进行实例化</p>
<dl class="attribute">
<dt id="scrapy.crawler.Crawler.settings">
<code class="descname">settings</code><a class="headerlink" href="#scrapy.crawler.Crawler.settings" title="永久链接至目标">¶</a></dt>
<dd><p>crawler的配置管理器。</p>
<p>扩展(extensions)和中间件(middlewares)使用它用来访问Scrapy的配置。</p>
<p>关于Scrapy配置的介绍参考这里 <a class="reference internal" href="settings.html#topics-settings"><span class="std std-ref">Settings</span></a>。</p>
<p>API参考 <a class="reference internal" href="#scrapy.settings.Settings" title="scrapy.settings.Settings"><code class="xref py py-class docutils literal"><span class="pre">Settings</span></code></a>。</p>
</dd></dl>

<dl class="attribute">
<dt id="scrapy.crawler.Crawler.signals">
<code class="descname">signals</code><a class="headerlink" href="#scrapy.crawler.Crawler.signals" title="永久链接至目标">¶</a></dt>
<dd><p>crawler的信号管理器。</p>
<p>扩展和中间件使用它将自己的功能挂载到Scrapy。</p>
<p>关于信号的介绍参考 <a class="reference internal" href="signals.html#topics-signals"><span class="std std-ref">信号(Signals)</span></a>。</p>
<p>API参考 <a class="reference internal" href="#scrapy.signalmanager.SignalManager" title="scrapy.signalmanager.SignalManager"><code class="xref py py-class docutils literal"><span class="pre">SignalManager</span></code></a>。</p>
</dd></dl>

<dl class="attribute">
<dt id="scrapy.crawler.Crawler.stats">
<code class="descname">stats</code><a class="headerlink" href="#scrapy.crawler.Crawler.stats" title="永久链接至目标">¶</a></dt>
<dd><p>crawler的统计信息收集器。</p>
<p>扩展和中间件使用它记录操作的统计信息，或者访问由其他扩展收集的统计信息。</p>
<p>关于统计信息收集器的介绍参考 <a class="reference internal" href="stats.html#topics-stats"><span class="std std-ref">数据收集(Stats Collection)</span></a>。</p>
<p>API参考类 <a class="reference internal" href="#scrapy.statscol.StatsCollector" title="scrapy.statscol.StatsCollector"><code class="xref py py-class docutils literal"><span class="pre">StatsCollector</span></code></a> class。</p>
</dd></dl>

<dl class="attribute">
<dt id="scrapy.crawler.Crawler.extensions">
<code class="descname">extensions</code><a class="headerlink" href="#scrapy.crawler.Crawler.extensions" title="永久链接至目标">¶</a></dt>
<dd><p>扩展管理器，跟踪所有开启的扩展。</p>
<p>大多数扩展不需要访问该属性。</p>
<p>关于扩展和可用扩展列表器的介绍参考 <a class="reference internal" href="extensions.html#topics-extensions"><span class="std std-ref">扩展(Extensions)</span></a>。</p>
</dd></dl>

<dl class="attribute">
<dt id="scrapy.crawler.Crawler.engine">
<code class="descname">engine</code><a class="headerlink" href="#scrapy.crawler.Crawler.engine" title="永久链接至目标">¶</a></dt>
<dd><p>执行引擎，协调crawler的核心逻辑，包括调度，下载和spider。</p>
<p>某些扩展可能需要访问Scrapy的引擎属性，以修改检查(modify inspect)或修改下载器和调度器的行为，
这是该API的高级使用，但还不稳定。</p>
</dd></dl>

<dl class="attribute">
<dt id="scrapy.crawler.Crawler.spider">
<code class="descname">spider</code><a class="headerlink" href="#scrapy.crawler.Crawler.spider" title="永久链接至目标">¶</a></dt>
<dt>
<code class="descname">正在爬取的spider。该spider类的实例由创建crawler时所提供，</code></dt>
<dt>
<code class="descname">在调用 :meth:`crawl` 方法是所创建。</code></dt>
<dd></dd></dl>

<dl class="method">
<dt id="scrapy.crawler.Crawler.crawl">
<code class="descname">crawl</code><span class="sig-paren">(</span><em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#scrapy.crawler.Crawler.crawl" title="永久链接至目标">¶</a></dt>
<dd><p>根据给定的
<cite>args</cite> , <cite>kwargs</cite> 的参数来初始化spider类，启动执行引擎，启动crawler。</p>
<p>返回一个延迟deferred对象，当爬取结束时触发它。</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="scrapy.crawler.CrawlerRunner">
<em class="property">class </em><code class="descclassname">scrapy.crawler.</code><code class="descname">CrawlerRunner</code><span class="sig-paren">(</span><em>settings</em><span class="sig-paren">)</span><a class="headerlink" href="#scrapy.crawler.CrawlerRunner" title="永久链接至目标">¶</a></dt>
<dd><p>This is a convenient helper class that creates, configures and runs
crawlers inside an already setup Twisted <a class="reference external" href="http://twistedmatrix.com/documents/current/core/howto/reactor-basics.html">reactor</a>.</p>
<p>The CrawlerRunner object must be instantiated with a
<a class="reference internal" href="#scrapy.settings.Settings" title="scrapy.settings.Settings"><code class="xref py py-class docutils literal"><span class="pre">Settings</span></code></a> object.</p>
<p>This class shouldn&#8217;t be needed (since Scrapy is responsible of using it
accordingly) unless writing scripts that manually handle the crawling
process. See <a class="reference internal" href="practices.html#run-from-script"><span class="std std-ref">在脚本中运行Scrapy</span></a> for an example.</p>
<dl class="attribute">
<dt id="scrapy.crawler.CrawlerRunner.crawlers">
<code class="descname">crawlers</code><a class="headerlink" href="#scrapy.crawler.CrawlerRunner.crawlers" title="永久链接至目标">¶</a></dt>
<dd><p>Set of <a class="reference internal" href="#scrapy.crawler.Crawler" title="scrapy.crawler.Crawler"><code class="xref py py-class docutils literal"><span class="pre">crawlers</span></code></a> created by the
<a class="reference internal" href="#scrapy.crawler.CrawlerRunner.crawl" title="scrapy.crawler.CrawlerRunner.crawl"><code class="xref py py-meth docutils literal"><span class="pre">crawl()</span></code></a> method.</p>
</dd></dl>

<dl class="attribute">
<dt id="scrapy.crawler.CrawlerRunner.crawl_deferreds">
<code class="descname">crawl_deferreds</code><a class="headerlink" href="#scrapy.crawler.CrawlerRunner.crawl_deferreds" title="永久链接至目标">¶</a></dt>
<dd><p>Set of the <a class="reference external" href="http://twistedmatrix.com/documents/current/core/howto/defer.html">deferreds</a> return by the <a class="reference internal" href="#scrapy.crawler.CrawlerRunner.crawl" title="scrapy.crawler.CrawlerRunner.crawl"><code class="xref py py-meth docutils literal"><span class="pre">crawl()</span></code></a> method. This
collection it&#8217;s useful for keeping track of current crawling state.</p>
</dd></dl>

<dl class="method">
<dt id="scrapy.crawler.CrawlerRunner.crawl">
<code class="descname">crawl</code><span class="sig-paren">(</span><em>spidercls</em>, <em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#scrapy.crawler.CrawlerRunner.crawl" title="永久链接至目标">¶</a></dt>
<dd><p>This method sets up the crawling of the given <cite>spidercls</cite> with the
provided arguments.</p>
<p>It takes care of loading the spider class while configuring and starting
a crawler for it.</p>
<p>Returns a deferred that is fired when the crawl is finished.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">参数:</th><td class="field-body"><ul class="first last simple">
<li><strong>spidercls</strong> (<a class="reference internal" href="spiders.html#scrapy.spider.Spider" title="scrapy.spider.Spider"><code class="xref py py-class docutils literal"><span class="pre">Spider</span></code></a> subclass or str) &#8211; spider class or spider&#8217;s name inside the project</li>
<li><strong>args</strong> (<a class="reference internal" href="#scrapy.spidermanager.SpiderManager.list" title="scrapy.spidermanager.SpiderManager.list"><em>list</em></a>) &#8211; arguments to initializate the spider</li>
<li><strong>kwargs</strong> (<em>dict</em>) &#8211; keyword arguments to initializate the spider</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="scrapy.crawler.CrawlerRunner.stop">
<code class="descname">stop</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#scrapy.crawler.CrawlerRunner.stop" title="永久链接至目标">¶</a></dt>
<dd><p>Stops simultaneously all the crawling jobs taking place.</p>
<p>Returns a deferred that is fired when they all have ended.</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-scrapy.settings">
<span id="settings-api"></span><span id="topics-api-settings"></span><h2>设置(Settings) API<a class="headerlink" href="#module-scrapy.settings" title="永久链接至标题">¶</a></h2>
<dl class="attribute">
<dt id="scrapy.settings.SETTINGS_PRIORITIES">
<code class="descclassname">scrapy.settings.</code><code class="descname">SETTINGS_PRIORITIES</code><a class="headerlink" href="#scrapy.settings.SETTINGS_PRIORITIES" title="永久链接至目标">¶</a></dt>
<dd><p>Dictionary that sets the key name and priority level of the default
settings priorities used in Scrapy.</p>
<p>Each item defines a settings entry point, giving it a code name for
identification and an integer priority. Greater priorities take more
precedence over lesser ones when setting and retrieving values in the
<a class="reference internal" href="#scrapy.settings.Settings" title="scrapy.settings.Settings"><code class="xref py py-class docutils literal"><span class="pre">Settings</span></code></a> class.</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">SETTINGS_PRIORITIES</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;default&#39;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
    <span class="s1">&#39;command&#39;</span><span class="p">:</span> <span class="mi">10</span><span class="p">,</span>
    <span class="s1">&#39;project&#39;</span><span class="p">:</span> <span class="mi">20</span><span class="p">,</span>
    <span class="s1">&#39;spider&#39;</span><span class="p">:</span> <span class="mi">30</span><span class="p">,</span>
    <span class="s1">&#39;cmdline&#39;</span><span class="p">:</span> <span class="mi">40</span><span class="p">,</span>
<span class="p">}</span>
</pre></div>
</div>
<p>For a detailed explanation on each settings sources, see:
<a class="reference internal" href="settings.html#topics-settings"><span class="std std-ref">Settings</span></a>.</p>
</dd></dl>

<dl class="class">
<dt id="scrapy.settings.Settings">
<em class="property">class </em><code class="descclassname">scrapy.settings.</code><code class="descname">Settings</code><span class="sig-paren">(</span><em>values={}</em>, <em>priority='project'</em><span class="sig-paren">)</span><a class="headerlink" href="#scrapy.settings.Settings" title="永久链接至目标">¶</a></dt>
<dd><p>This object stores Scrapy settings for the configuration of internal
components, and can be used for any further customization.</p>
<p>After instantiation of this class, the new object will have the global
default settings described on <a class="reference internal" href="settings.html#topics-settings-ref"><span class="std std-ref">内置设定参考手册</span></a> already
populated.</p>
<p>Additional values can be passed on initialization with the <code class="docutils literal"><span class="pre">values</span></code>
argument, and they would take the <code class="docutils literal"><span class="pre">priority</span></code> level.  If the latter
argument is a string, the priority name will be looked up in
<a class="reference internal" href="#scrapy.settings.SETTINGS_PRIORITIES" title="scrapy.settings.SETTINGS_PRIORITIES"><code class="xref py py-attr docutils literal"><span class="pre">SETTINGS_PRIORITIES</span></code></a>. Otherwise, a expecific
integer should be provided.</p>
<p>Once the object is created, new settings can be loaded or updated with the
<a class="reference internal" href="#scrapy.settings.Settings.set" title="scrapy.settings.Settings.set"><code class="xref py py-meth docutils literal"><span class="pre">set()</span></code></a> method, and can be accessed with the
square bracket notation of dictionaries, or with the
<a class="reference internal" href="#scrapy.settings.Settings.get" title="scrapy.settings.Settings.get"><code class="xref py py-meth docutils literal"><span class="pre">get()</span></code></a> method of the instance and its value
conversion variants.  When requesting a stored key, the value with the
highest priority will be retrieved.</p>
<dl class="method">
<dt id="scrapy.settings.Settings.set">
<code class="descname">set</code><span class="sig-paren">(</span><em>name</em>, <em>value</em>, <em>priority='project'</em><span class="sig-paren">)</span><a class="headerlink" href="#scrapy.settings.Settings.set" title="永久链接至目标">¶</a></dt>
<dd><p>Store a key/value attribute with a given priority.
Settings should be populated <em>before</em> configuring the Crawler object
(through the <code class="xref py py-meth docutils literal"><span class="pre">configure()</span></code> method),
otherwise they won&#8217;t have any effect.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">参数:</th><td class="field-body"><ul class="first last simple">
<li><strong>name</strong> (<em>string</em>) &#8211; the setting name</li>
<li><strong>value</strong> (<em>any</em>) &#8211; the value to associate with the setting</li>
<li><strong>priority</strong> (<em>string or int</em>) &#8211; the priority of the setting. Should be a key of
<a class="reference internal" href="#scrapy.settings.SETTINGS_PRIORITIES" title="scrapy.settings.SETTINGS_PRIORITIES"><code class="xref py py-attr docutils literal"><span class="pre">SETTINGS_PRIORITIES</span></code></a> or an integer</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="scrapy.settings.Settings.setdict">
<code class="descname">setdict</code><span class="sig-paren">(</span><em>values</em>, <em>priority='project'</em><span class="sig-paren">)</span><a class="headerlink" href="#scrapy.settings.Settings.setdict" title="永久链接至目标">¶</a></dt>
<dd><p>Store key/value pairs with a given priority.</p>
<p>This is a helper function that calls
<a class="reference internal" href="#scrapy.settings.Settings.set" title="scrapy.settings.Settings.set"><code class="xref py py-meth docutils literal"><span class="pre">set()</span></code></a> for every item of <code class="docutils literal"><span class="pre">values</span></code>
with the provided <code class="docutils literal"><span class="pre">priority</span></code>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">参数:</th><td class="field-body"><ul class="first last simple">
<li><strong>values</strong> (<em>dict</em>) &#8211; the settings names and values</li>
<li><strong>priority</strong> (<em>string or int</em>) &#8211; the priority of the settings. Should be a key of
<a class="reference internal" href="#scrapy.settings.SETTINGS_PRIORITIES" title="scrapy.settings.SETTINGS_PRIORITIES"><code class="xref py py-attr docutils literal"><span class="pre">SETTINGS_PRIORITIES</span></code></a> or an integer</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="scrapy.settings.Settings.setmodule">
<code class="descname">setmodule</code><span class="sig-paren">(</span><em>module</em>, <em>priority='project'</em><span class="sig-paren">)</span><a class="headerlink" href="#scrapy.settings.Settings.setmodule" title="永久链接至目标">¶</a></dt>
<dd><p>Store settings from a module with a given priority.</p>
<p>This is a helper function that calls
<a class="reference internal" href="#scrapy.settings.Settings.set" title="scrapy.settings.Settings.set"><code class="xref py py-meth docutils literal"><span class="pre">set()</span></code></a> for every globally declared
uppercase variable of <code class="docutils literal"><span class="pre">module</span></code> with the provided <code class="docutils literal"><span class="pre">priority</span></code>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">参数:</th><td class="field-body"><ul class="first last simple">
<li><strong>module</strong> (<em>module object or string</em>) &#8211; the module or the path of the module</li>
<li><strong>priority</strong> (<em>string or int</em>) &#8211; the priority of the settings. Should be a key of
<a class="reference internal" href="#scrapy.settings.SETTINGS_PRIORITIES" title="scrapy.settings.SETTINGS_PRIORITIES"><code class="xref py py-attr docutils literal"><span class="pre">SETTINGS_PRIORITIES</span></code></a> or an integer</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="scrapy.settings.Settings.get">
<code class="descname">get</code><span class="sig-paren">(</span><em>name</em>, <em>default=None</em><span class="sig-paren">)</span><a class="headerlink" href="#scrapy.settings.Settings.get" title="永久链接至目标">¶</a></dt>
<dd><p>获取某项配置的值，且不修改其原有的值。</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">参数:</th><td class="field-body"><ul class="first last simple">
<li><strong>name</strong> (<em>字符串</em>) &#8211; 配置名</li>
<li><strong>default</strong> (<em>任何</em>) &#8211; 如果没有该项配置时返回的缺省值</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="scrapy.settings.Settings.getbool">
<code class="descname">getbool</code><span class="sig-paren">(</span><em>name</em>, <em>default=False</em><span class="sig-paren">)</span><a class="headerlink" href="#scrapy.settings.Settings.getbool" title="永久链接至目标">¶</a></dt>
<dd><p>return <code class="docutils literal"><span class="pre">False</span></code>
将某项配置的值以布尔值形式返回。比如，<code class="docutils literal"><span class="pre">1</span></code> 和 <code class="docutils literal"><span class="pre">'1'</span></code>，<code class="docutils literal"><span class="pre">True</span></code> 都返回``True``，
而 <code class="docutils literal"><span class="pre">0</span></code>，<code class="docutils literal"><span class="pre">'0'</span></code>，<code class="docutils literal"><span class="pre">False</span></code> 和 <code class="docutils literal"><span class="pre">None</span></code> 返回 <code class="docutils literal"><span class="pre">False</span></code>。</p>
<p>比如，通过环境变量计算将某项配置设置为 <code class="docutils literal"><span class="pre">'0'</span></code>，通过该方法获取得到 <code class="docutils literal"><span class="pre">False</span></code>。</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">参数:</th><td class="field-body"><ul class="first last simple">
<li><strong>name</strong> (<em>字符串</em>) &#8211; 配置名</li>
<li><strong>default</strong> (<em>任何</em>) &#8211; 如果该配置项未设置，返回的缺省值</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="scrapy.settings.Settings.getint">
<code class="descname">getint</code><span class="sig-paren">(</span><em>name</em>, <em>default=0</em><span class="sig-paren">)</span><a class="headerlink" href="#scrapy.settings.Settings.getint" title="永久链接至目标">¶</a></dt>
<dd><p>将某项配置的值以整数形式返回</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">参数:</th><td class="field-body"><ul class="first last simple">
<li><strong>name</strong> (<em>字符串</em>) &#8211; 配置名</li>
<li><strong>default</strong> (<em>任何</em>) &#8211; 如果该配置项未设置，返回的缺省值</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="scrapy.settings.Settings.getfloat">
<code class="descname">getfloat</code><span class="sig-paren">(</span><em>name</em>, <em>default=0.0</em><span class="sig-paren">)</span><a class="headerlink" href="#scrapy.settings.Settings.getfloat" title="永久链接至目标">¶</a></dt>
<dd><p>将某项配置的值以浮点数形式返回</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">参数:</th><td class="field-body"><ul class="first last simple">
<li><strong>name</strong> (<em>字符串</em>) &#8211; 配置名</li>
<li><strong>default</strong> (<em>任何</em>) &#8211; 如果该配置项未设置，返回的缺省值</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="scrapy.settings.Settings.getlist">
<code class="descname">getlist</code><span class="sig-paren">(</span><em>name</em>, <em>default=None</em><span class="sig-paren">)</span><a class="headerlink" href="#scrapy.settings.Settings.getlist" title="永久链接至目标">¶</a></dt>
<dd><p>将某项配置的值以列表形式返回。如果配置值本来就是list则将返回其拷贝。
如果是字符串，则返回被 &#8221;,&#8221; 分割后的列表。</p>
<p>比如，某项值通过环境变量的计算被设置为 <code class="docutils literal"><span class="pre">'one,two'</span></code> ，该方法返回[&#8216;one&#8217;, &#8216;two&#8217;]。</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">参数:</th><td class="field-body"><ul class="first last simple">
<li><strong>name</strong> (<em>字符串</em>) &#8211; 配置名</li>
<li><strong>default</strong> (<em>任何类型</em>) &#8211; 如果该配置项未设置，返回的缺省值</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="scrapy.settings.Settings.getdict">
<code class="descname">getdict</code><span class="sig-paren">(</span><em>name</em>, <em>default=None</em><span class="sig-paren">)</span><a class="headerlink" href="#scrapy.settings.Settings.getdict" title="永久链接至目标">¶</a></dt>
<dd><p>Get a setting value as a dictionary. If the setting original type is a
dictionary, a copy of it will be returned. If it&#8217;s a string it will
evaluated as a json dictionary.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">参数:</th><td class="field-body"><ul class="first last simple">
<li><strong>name</strong> (<em>string</em>) &#8211; the setting name</li>
<li><strong>default</strong> (<em>any</em>) &#8211; the value to return if no setting is found</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="scrapy.settings.Settings.copy">
<code class="descname">copy</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#scrapy.settings.Settings.copy" title="永久链接至目标">¶</a></dt>
<dd><p>Make a deep copy of current settings.</p>
<p>This method returns a new instance of the <a class="reference internal" href="#scrapy.settings.Settings" title="scrapy.settings.Settings"><code class="xref py py-class docutils literal"><span class="pre">Settings</span></code></a> class,
populated with the same values and their priorities.</p>
<p>Modifications to the new object won&#8217;t be reflected on the original
settings.</p>
</dd></dl>

<dl class="method">
<dt id="scrapy.settings.Settings.freeze">
<code class="descname">freeze</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#scrapy.settings.Settings.freeze" title="永久链接至目标">¶</a></dt>
<dd><p>Disable further changes to the current settings.</p>
<p>After calling this method, the present state of the settings will become
immutable. Trying to change values through the <a class="reference internal" href="#scrapy.settings.Settings.set" title="scrapy.settings.Settings.set"><code class="xref py py-meth docutils literal"><span class="pre">set()</span></code></a> method and
its variants won&#8217;t be possible and will be alerted.</p>
</dd></dl>

<dl class="method">
<dt id="scrapy.settings.Settings.frozencopy">
<code class="descname">frozencopy</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#scrapy.settings.Settings.frozencopy" title="永久链接至目标">¶</a></dt>
<dd><p>Return an immutable copy of the current settings.</p>
<p>Alias for a <a class="reference internal" href="#scrapy.settings.Settings.freeze" title="scrapy.settings.Settings.freeze"><code class="xref py py-meth docutils literal"><span class="pre">freeze()</span></code></a> call in the object returned by <a class="reference internal" href="#scrapy.settings.Settings.copy" title="scrapy.settings.Settings.copy"><code class="xref py py-meth docutils literal"><span class="pre">copy()</span></code></a></p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-scrapy.spidermanager">
<span id="spidermanager-api"></span><span id="topics-api-spidermanager"></span><h2>SpiderManager API<a class="headerlink" href="#module-scrapy.spidermanager" title="永久链接至标题">¶</a></h2>
<dl class="class">
<dt id="scrapy.spidermanager.SpiderManager">
<em class="property">class </em><code class="descclassname">scrapy.spidermanager.</code><code class="descname">SpiderManager</code><a class="headerlink" href="#scrapy.spidermanager.SpiderManager" title="永久链接至目标">¶</a></dt>
<dd><p>This class is in charge of retrieving and handling the spider classes
defined across the project.</p>
<p>Custom spider managers can be employed by specifying their path in the
<a class="reference internal" href="settings.html#std:setting-SPIDER_MANAGER_CLASS"><code class="xref std std-setting docutils literal"><span class="pre">SPIDER_MANAGER_CLASS</span></code></a> project setting. They must fully implement
the <code class="xref py py-class docutils literal"><span class="pre">scrapy.interfaces.ISpiderManager</span></code> interface to guarantee an
errorless execution.</p>
<dl class="method">
<dt id="scrapy.spidermanager.SpiderManager.from_settings">
<code class="descname">from_settings</code><span class="sig-paren">(</span><em>settings</em><span class="sig-paren">)</span><a class="headerlink" href="#scrapy.spidermanager.SpiderManager.from_settings" title="永久链接至目标">¶</a></dt>
<dd><p>This class method is used by Scrapy to create an instance of the class.
It&#8217;s called with the current project settings, and it loads the spiders
found in the modules of the <a class="reference internal" href="settings.html#std:setting-SPIDER_MODULES"><code class="xref std std-setting docutils literal"><span class="pre">SPIDER_MODULES</span></code></a> setting.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">参数:</th><td class="field-body"><strong>settings</strong> (<a class="reference internal" href="#scrapy.settings.Settings" title="scrapy.settings.Settings"><code class="xref py py-class docutils literal"><span class="pre">Settings</span></code></a> instance) &#8211; project settings</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="scrapy.spidermanager.SpiderManager.load">
<code class="descname">load</code><span class="sig-paren">(</span><em>spider_name</em><span class="sig-paren">)</span><a class="headerlink" href="#scrapy.spidermanager.SpiderManager.load" title="永久链接至目标">¶</a></dt>
<dd><p>Get the Spider class with the given name. It&#8217;ll look into the previously
loaded spiders for a spider class with name <cite>spider_name</cite> and will raise
a KeyError if not found.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">参数:</th><td class="field-body"><strong>spider_name</strong> (<em>str</em>) &#8211; spider class name</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="scrapy.spidermanager.SpiderManager.list">
<code class="descname">list</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#scrapy.spidermanager.SpiderManager.list" title="永久链接至目标">¶</a></dt>
<dd><p>Get the names of the available spiders in the project.</p>
</dd></dl>

<dl class="method">
<dt id="scrapy.spidermanager.SpiderManager.find_by_request">
<code class="descname">find_by_request</code><span class="sig-paren">(</span><em>request</em><span class="sig-paren">)</span><a class="headerlink" href="#scrapy.spidermanager.SpiderManager.find_by_request" title="永久链接至目标">¶</a></dt>
<dd><p>List the spiders&#8217; names that can handle the given request. Will try to
match the request&#8217;s url against the domains of the spiders.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">参数:</th><td class="field-body"><strong>request</strong> (<a class="reference internal" href="request-response.html#scrapy.http.Request" title="scrapy.http.Request"><code class="xref py py-class docutils literal"><span class="pre">Request</span></code></a> instance) &#8211; queried request</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-scrapy.signalmanager">
<span id="signals-api"></span><span id="topics-api-signals"></span><h2>信号(Signals) API<a class="headerlink" href="#module-scrapy.signalmanager" title="永久链接至标题">¶</a></h2>
<dl class="class">
<dt id="scrapy.signalmanager.SignalManager">
<em class="property">class </em><code class="descclassname">scrapy.signalmanager.</code><code class="descname">SignalManager</code><a class="headerlink" href="#scrapy.signalmanager.SignalManager" title="永久链接至目标">¶</a></dt>
<dd><dl class="method">
<dt id="scrapy.signalmanager.SignalManager.connect">
<code class="descname">connect</code><span class="sig-paren">(</span><em>receiver</em>, <em>signal</em><span class="sig-paren">)</span><a class="headerlink" href="#scrapy.signalmanager.SignalManager.connect" title="永久链接至目标">¶</a></dt>
<dd><p>链接一个接收器函数(receiver function) 到一个信号(signal)。</p>
<p>signal可以是任何对象，虽然Scrapy提供了一些预先定义好的信号，
参考文档 <a class="reference internal" href="signals.html#topics-signals"><span class="std std-ref">信号(Signals)</span></a>。</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">参数:</th><td class="field-body"><ul class="first last simple">
<li><strong>receiver</strong> (<em>可调用对象</em>) &#8211; 被链接到的函数</li>
<li><strong>signal</strong> (<em>对象</em>) &#8211; 链接的信号</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="scrapy.signalmanager.SignalManager.send_catch_log">
<code class="descname">send_catch_log</code><span class="sig-paren">(</span><em>signal</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#scrapy.signalmanager.SignalManager.send_catch_log" title="永久链接至目标">¶</a></dt>
<dd><p>发送一个信号，捕获异常并记录日志。</p>
<p>关键字参数会传递给信号处理者(signal handlers)(通过方法 <a class="reference internal" href="#scrapy.signalmanager.SignalManager.connect" title="scrapy.signalmanager.SignalManager.connect"><code class="xref py py-meth docutils literal"><span class="pre">connect()</span></code></a> 关联)。</p>
</dd></dl>

<dl class="method">
<dt id="scrapy.signalmanager.SignalManager.send_catch_log_deferred">
<code class="descname">send_catch_log_deferred</code><span class="sig-paren">(</span><em>signal</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#scrapy.signalmanager.SignalManager.send_catch_log_deferred" title="永久链接至目标">¶</a></dt>
<dd><p>跟 <a class="reference internal" href="#scrapy.signalmanager.SignalManager.send_catch_log" title="scrapy.signalmanager.SignalManager.send_catch_log"><code class="xref py py-meth docutils literal"><span class="pre">send_catch_log()</span></code></a> 相似但支持返回 <a class="reference external" href="http://twistedmatrix.com/documents/current/core/howto/defer.html">deferreds</a> 形式的信号处理器。</p>
<p>返回一个 <a class="reference external" href="http://twistedmatrix.com/documents/current/core/howto/defer.html">deferred</a> ，当所有的信号处理器的延迟被触发时调用。
发送一个信号，处理异常并记录日志。</p>
<p>关键字参数会传递给信号处理者(signal handlers)(通过方法 <a class="reference internal" href="#scrapy.signalmanager.SignalManager.connect" title="scrapy.signalmanager.SignalManager.connect"><code class="xref py py-meth docutils literal"><span class="pre">connect()</span></code></a> 关联)。</p>
</dd></dl>

<dl class="method">
<dt id="scrapy.signalmanager.SignalManager.disconnect">
<code class="descname">disconnect</code><span class="sig-paren">(</span><em>receiver</em>, <em>signal</em><span class="sig-paren">)</span><a class="headerlink" href="#scrapy.signalmanager.SignalManager.disconnect" title="永久链接至目标">¶</a></dt>
<dd><p>解除一个接收器函数和一个信号的关联。这跟方法 <a class="reference internal" href="#scrapy.signalmanager.SignalManager.connect" title="scrapy.signalmanager.SignalManager.connect"><code class="xref py py-meth docutils literal"><span class="pre">connect()</span></code></a> 有相反的作用，
参数也相同。</p>
</dd></dl>

<dl class="method">
<dt id="scrapy.signalmanager.SignalManager.disconnect_all">
<code class="descname">disconnect_all</code><span class="sig-paren">(</span><em>signal</em><span class="sig-paren">)</span><a class="headerlink" href="#scrapy.signalmanager.SignalManager.disconnect_all" title="永久链接至目标">¶</a></dt>
<dd><p>取消给定信号绑定的所有接收器。</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">参数:</th><td class="field-body"><strong>signal</strong> (<em>object</em>) &#8211; 要取消绑定的信号</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="stats-collector-api">
<span id="topics-api-stats"></span><h2>状态收集器(Stats Collector) API<a class="headerlink" href="#stats-collector-api" title="永久链接至标题">¶</a></h2>
<p>模块 <cite>scrapy.statscol</cite> 下有好几种状态收集器，
它们都实现了状态收集器API对应的类 <code class="xref py py-class docutils literal"><span class="pre">Statscollector</span></code> (即它们都继承至该类)。</p>
<span class="target" id="module-scrapy.statscol"></span><dl class="class">
<dt id="scrapy.statscol.StatsCollector">
<em class="property">class </em><code class="descclassname">scrapy.statscol.</code><code class="descname">StatsCollector</code><a class="headerlink" href="#scrapy.statscol.StatsCollector" title="永久链接至目标">¶</a></dt>
<dd><dl class="method">
<dt id="scrapy.statscol.StatsCollector.get_value">
<code class="descname">get_value</code><span class="sig-paren">(</span><em>key</em>, <em>default=None</em><span class="sig-paren">)</span><a class="headerlink" href="#scrapy.statscol.StatsCollector.get_value" title="永久链接至目标">¶</a></dt>
<dd><p>返回指定key的统计值，如果key不存在则返回缺省值。</p>
</dd></dl>

<dl class="method">
<dt id="scrapy.statscol.StatsCollector.get_stats">
<code class="descname">get_stats</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#scrapy.statscol.StatsCollector.get_stats" title="永久链接至目标">¶</a></dt>
<dd><p>以dict形式返回当前spider的所有统计值。</p>
</dd></dl>

<dl class="method">
<dt id="scrapy.statscol.StatsCollector.set_value">
<code class="descname">set_value</code><span class="sig-paren">(</span><em>key</em>, <em>value</em><span class="sig-paren">)</span><a class="headerlink" href="#scrapy.statscol.StatsCollector.set_value" title="永久链接至目标">¶</a></dt>
<dd><p>设置key所指定的统计值为value。</p>
</dd></dl>

<dl class="method">
<dt id="scrapy.statscol.StatsCollector.set_stats">
<code class="descname">set_stats</code><span class="sig-paren">(</span><em>stats</em><span class="sig-paren">)</span><a class="headerlink" href="#scrapy.statscol.StatsCollector.set_stats" title="永久链接至目标">¶</a></dt>
<dd><p>使用dict形式的 <code class="docutils literal"><span class="pre">stats</span></code> 参数覆盖当前的统计值。</p>
</dd></dl>

<dl class="method">
<dt id="scrapy.statscol.StatsCollector.inc_value">
<code class="descname">inc_value</code><span class="sig-paren">(</span><em>key</em>, <em>count=1</em>, <em>start=0</em><span class="sig-paren">)</span><a class="headerlink" href="#scrapy.statscol.StatsCollector.inc_value" title="永久链接至目标">¶</a></dt>
<dd><p>增加key所对应的统计值，增长值由count指定。
如果key未设置，则使用start的值设置为初始值。</p>
</dd></dl>

<dl class="method">
<dt id="scrapy.statscol.StatsCollector.max_value">
<code class="descname">max_value</code><span class="sig-paren">(</span><em>key</em>, <em>value</em><span class="sig-paren">)</span><a class="headerlink" href="#scrapy.statscol.StatsCollector.max_value" title="永久链接至目标">¶</a></dt>
<dd><p>如果key所对应的当前value小于参数所指定的value，则设置value。
如果没有key所对应的value，设置value。</p>
</dd></dl>

<dl class="method">
<dt id="scrapy.statscol.StatsCollector.min_value">
<code class="descname">min_value</code><span class="sig-paren">(</span><em>key</em>, <em>value</em><span class="sig-paren">)</span><a class="headerlink" href="#scrapy.statscol.StatsCollector.min_value" title="永久链接至目标">¶</a></dt>
<dd><p>如果key所对应的当前value大于参数所指定的value，则设置value。
如果没有key所对应的value，设置value。</p>
</dd></dl>

<dl class="method">
<dt id="scrapy.statscol.StatsCollector.clear_stats">
<code class="descname">clear_stats</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#scrapy.statscol.StatsCollector.clear_stats" title="永久链接至目标">¶</a></dt>
<dd><p>清除所有统计信息。</p>
</dd></dl>

<p>以下方法不是统计收集api的一部分，但实现自定义的统计收集器时会使用到：</p>
<dl class="method">
<dt id="scrapy.statscol.StatsCollector.open_spider">
<code class="descname">open_spider</code><span class="sig-paren">(</span><em>spider</em><span class="sig-paren">)</span><a class="headerlink" href="#scrapy.statscol.StatsCollector.open_spider" title="永久链接至目标">¶</a></dt>
<dd><p>打开指定spider进行统计信息收集。</p>
</dd></dl>

<dl class="method">
<dt id="scrapy.statscol.StatsCollector.close_spider">
<code class="descname">close_spider</code><span class="sig-paren">(</span><em>spider</em><span class="sig-paren">)</span><a class="headerlink" href="#scrapy.statscol.StatsCollector.close_spider" title="永久链接至目标">¶</a></dt>
<dd><p>关闭指定spider。调用后，不能访问和收集统计信息。</p>
</dd></dl>

</dd></dl>

</div>
</div>


    

          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
  <h3><a href="../index.html">內容目录</a></h3>
  <ul>
<li><a class="reference internal" href="#">核心API</a><ul>
<li><a class="reference internal" href="#crawler-api">Crawler API</a></li>
<li><a class="reference internal" href="#module-scrapy.settings">设置(Settings) API</a></li>
<li><a class="reference internal" href="#module-scrapy.spidermanager">SpiderManager API</a></li>
<li><a class="reference internal" href="#module-scrapy.signalmanager">信号(Signals) API</a></li>
<li><a class="reference internal" href="#stats-collector-api">状态收集器(Stats Collector) API</a></li>
</ul>
</li>
</ul>
<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../index.html">Documentation overview</a><ul>
      <li>Previous: <a href="extensions.html" title="上一章">扩展(Extensions)</a></li>
      <li>Next: <a href="request-response.html" title="下一章">Requests and Responses</a></li>
  </ul></li>
</ul>
</div>
  <div role="note" aria-label="source link">
    <h3>本页</h3>
    <ul class="this-page-menu">
      <li><a href="../sources/topics/api.txt"
            rel="nofollow">显示源代码</a></li>
    </ul>
   </div>
<div id="searchbox" style="display: none" role="search">
  <h3>快速搜索</h3>
    <form class="search" action="../search.html" method="get">
      <div><input type="text" name="q" /></div>
      <div><input type="submit" value="转向" /></div>
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    
    <div class="footer">
      &copy;2008-2014, written by Scrapy developers, translated by Summer&Friends.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 1.4.6</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.9</a>
      
      |
      <a href="../sources/topics/api.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
    

  </body>
</html>