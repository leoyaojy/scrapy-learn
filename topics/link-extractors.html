<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml" lang="zh_CN">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>Link Extractors &#8212; Scrapy 0.24.1 文档</title>
    
    <link rel="stylesheet" href="../static/scrapydoc.css" type="text/css" />
    <link rel="stylesheet" href="../static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../',
        VERSION:     '0.24.1',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="../static/jquery.js"></script>
    <script type="text/javascript" src="../static/underscore.js"></script>
    <script type="text/javascript" src="../static/doctools.js"></script>
    <script type="text/javascript" src="../static/translations.js"></script>
    <link rel="top" title="Scrapy 0.24.1 文档" href="../index.html" />
    <link rel="next" title="Logging" href="logging.html" />
    <link rel="prev" title="Feed exports" href="feed-exports.html" />
   
  <link rel="stylesheet" href="../static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head>
  <body role="document">
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
    
  <div class="section" id="link-extractors">
<span id="topics-link-extractors"></span><h1>Link Extractors<a class="headerlink" href="#link-extractors" title="永久链接至标题">¶</a></h1>
<p>Link Extractors 是用于从网页(<a class="reference internal" href="request-response.html#scrapy.http.Response" title="scrapy.http.Response"><code class="xref py py-class docutils literal"><span class="pre">scrapy.http.Response</span></code></a> )中抽取会被follow的链接的对象。</p>
<p>Scrapy默认提供2种可用的 Link Extractor, 但你通过实现一个简单的接口创建自己定制的Link Extractor来满足需求｡
Scrapy 提供了 <code class="docutils literal"><span class="pre">scrapy.contrib.linkextractors</span> <span class="pre">import</span> <span class="pre">LinkExtractor</span></code> ，
不过您也可以通过实现一个简单的接口来创建您自己的Link Extractor，满足需求。</p>
<p>每个LinkExtractor有唯一的公共方法是 <code class="docutils literal"><span class="pre">extract_links</span></code> ，其接收 一个 <a class="reference internal" href="request-response.html#scrapy.http.Response" title="scrapy.http.Response"><code class="xref py py-class docutils literal"><span class="pre">Response</span></code></a> 对象，
并返回 <code class="xref py py-class docutils literal"><span class="pre">scrapy.link.Link</span></code> 对象｡
Link Extractors只实例化一次，其 <code class="docutils literal"><span class="pre">extract_links</span></code> 方法会根据不同的response被调用多次来提取链接｡</p>
<p>Link Extractors在 <a class="reference internal" href="spiders.html#scrapy.contrib.spiders.CrawlSpider" title="scrapy.contrib.spiders.CrawlSpider"><code class="xref py py-class docutils literal"><span class="pre">CrawlSpider</span></code></a> 类(在Scrapy可用)中使用, 通过一套规则,但你也可以用它在你的Spider中,即使你不是从 <a class="reference internal" href="spiders.html#scrapy.contrib.spiders.CrawlSpider" title="scrapy.contrib.spiders.CrawlSpider"><code class="xref py py-class docutils literal"><span class="pre">CrawlSpider</span></code></a> 继承的子类, 因为它的目的很简单: 提取链接｡</p>
<div class="section" id="module-scrapy.contrib.linkextractors">
<span id="link-extractor"></span><span id="topics-link-extractors-ref"></span><h2>内置Link Extractor 参考<a class="headerlink" href="#module-scrapy.contrib.linkextractors" title="永久链接至标题">¶</a></h2>
<p>Scrapy 自带的Link Extractors类在 <a class="reference internal" href="#module-scrapy.contrib.linkextractors" title="scrapy.contrib.linkextractors: Link extractors classes"><code class="xref py py-mod docutils literal"><span class="pre">scrapy.contrib.linkextractors</span></code></a> 模块提供｡</p>
<p>默认的link extractor 是 <code class="docutils literal"><span class="pre">LinkExtractor</span></code> ，其实就是
<a class="reference internal" href="#scrapy.contrib.linkextractors.lxmlhtml.LxmlLinkExtractor" title="scrapy.contrib.linkextractors.lxmlhtml.LxmlLinkExtractor"><code class="xref py py-class docutils literal"><span class="pre">LxmlLinkExtractor</span></code></a>:</p>
<div class="highlight-default"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">scrapy.contrib.linkextractors</span> <span class="k">import</span> <span class="n">LinkExtractor</span>
</pre></div>
</div>
<p>在以前版本的Scrapy版本中提供了其他的link extractor，不过都已经被废弃了。</p>
<div class="section" id="module-scrapy.contrib.linkextractors.lxmlhtml">
<span id="lxmllinkextractor"></span><h3>LxmlLinkExtractor<a class="headerlink" href="#module-scrapy.contrib.linkextractors.lxmlhtml" title="永久链接至标题">¶</a></h3>
<dl class="class">
<dt id="scrapy.contrib.linkextractors.lxmlhtml.LxmlLinkExtractor">
<em class="property">class </em><code class="descclassname">scrapy.contrib.linkextractors.lxmlhtml.</code><code class="descname">LxmlLinkExtractor</code><span class="sig-paren">(</span><em>allow=()</em>, <em>deny=()</em>, <em>allow_domains=()</em>, <em>deny_domains=()</em>, <em>deny_extensions=None</em>, <em>restrict_xpaths=()</em>, <em>tags=('a'</em>, <em>'area')</em>, <em>attrs=('href'</em>, <em>)</em>, <em>canonicalize=True</em>, <em>unique=True</em>, <em>process_value=None</em><span class="sig-paren">)</span><a class="headerlink" href="#scrapy.contrib.linkextractors.lxmlhtml.LxmlLinkExtractor" title="永久链接至目标">¶</a></dt>
<dd><p>LxmlLinkExtractor is the recommended link extractor with handy filtering
options. It is implemented using lxml&#8217;s robust HTMLParser.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">参数:</th><td class="field-body"><ul class="first last simple">
<li><strong>allow</strong> (<em>a regular expression (or list of)</em>) &#8211; a single regular expression (or list of regular expressions)
that the (absolute) urls must match in order to be extracted. If not
given (or empty), it will match all links.</li>
<li><strong>deny</strong> (<em>a regular expression (or list of)</em>) &#8211; a single regular expression (or list of regular expressions)
that the (absolute) urls must match in order to be excluded (ie. not
extracted). It has precedence over the <code class="docutils literal"><span class="pre">allow</span></code> parameter. If not
given (or empty) it won&#8217;t exclude any links.</li>
<li><strong>allow_domains</strong> (<em>str or list</em>) &#8211; a single value or a list of string containing
domains which will be considered for extracting the links</li>
<li><strong>deny_domains</strong> (<em>str or list</em>) &#8211; a single value or a list of strings containing
domains which won&#8217;t be considered for extracting the links</li>
<li><strong>deny_extensions</strong> (<a class="reference internal" href="api.html#scrapy.spidermanager.SpiderManager.list" title="scrapy.spidermanager.SpiderManager.list"><em>list</em></a>) &#8211; a single value or list of strings containing
extensions that should be ignored when extracting links.
If not given, it will default to the
<code class="docutils literal"><span class="pre">IGNORED_EXTENSIONS</span></code> list defined in the <a class="reference external" href="https://github.com/scrapy/scrapy/blob/master/scrapy/linkextractor.py">scrapy.linkextractor</a>
module.</li>
<li><strong>restrict_xpaths</strong> (<em>str or list</em>) &#8211; is a XPath (or list of XPath&#8217;s) which defines
regions inside the response where links should be extracted from.
If given, only the text selected by those XPath will be scanned for
links. See examples below.</li>
<li><strong>tags</strong> (<em>str or list</em>) &#8211; a tag or a list of tags to consider when extracting links.
Defaults to <code class="docutils literal"><span class="pre">('a',</span> <span class="pre">'area')</span></code>.</li>
<li><strong>attrs</strong> (<a class="reference internal" href="api.html#scrapy.spidermanager.SpiderManager.list" title="scrapy.spidermanager.SpiderManager.list"><em>list</em></a>) &#8211; an attribute or list of attributes which should be considered when looking
for links to extract (only for those tags specified in the <code class="docutils literal"><span class="pre">tags</span></code>
parameter). Defaults to <code class="docutils literal"><span class="pre">('href',)</span></code></li>
<li><strong>canonicalize</strong> (<em>boolean</em>) &#8211; canonicalize each extracted url (using
scrapy.utils.url.canonicalize_url). Defaults to <code class="docutils literal"><span class="pre">True</span></code>.</li>
<li><strong>unique</strong> (<em>boolean</em>) &#8211; whether duplicate filtering should be applied to extracted
links.</li>
<li><strong>process_value</strong> (<em>callable</em>) &#8211; <p>它接收来自扫描标签和属性提取每个值, 可以修改该值, 并返回一个新的, 或返回 <code class="docutils literal"><span class="pre">None</span></code> 完全忽略链接的功能｡如果没有给出,  <code class="docutils literal"><span class="pre">process_value</span></code> 默认是 <code class="docutils literal"><span class="pre">lambda</span> <span class="pre">x:</span> <span class="pre">x</span></code>｡</p>
<p>例如,从这段代码中提取链接:</p>
<div class="highlight-html"><div class="highlight"><pre><span class="p">&lt;</span><span class="nt">a</span> <span class="na">href</span><span class="o">=</span><span class="s">&quot;javascript:goToPage(&#39;../other/page.html&#39;); return false&quot;</span><span class="p">&gt;</span>Link text<span class="p">&lt;/</span><span class="nt">a</span><span class="p">&gt;</span>
</pre></div>
</div>
<p>你可以使用下面的这个 <code class="docutils literal"><span class="pre">process_value</span></code> 函数:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="k">def</span> <span class="nf">process_value</span><span class="p">(</span><span class="n">value</span><span class="p">):</span>
    <span class="n">m</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">search</span><span class="p">(</span><span class="s2">&quot;javascript:goToPage\(&#39;(.*?)&#39;&quot;</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">m</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">m</span><span class="o">.</span><span class="n">group</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</div>
</div>
</div>


    

          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
  <h3><a href="../index.html">內容目录</a></h3>
  <ul>
<li><a class="reference internal" href="#">Link Extractors</a><ul>
<li><a class="reference internal" href="#module-scrapy.contrib.linkextractors">内置Link Extractor 参考</a><ul>
<li><a class="reference internal" href="#module-scrapy.contrib.linkextractors.lxmlhtml">LxmlLinkExtractor</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../index.html">Documentation overview</a><ul>
      <li>Previous: <a href="feed-exports.html" title="上一章">Feed exports</a></li>
      <li>Next: <a href="logging.html" title="下一章">Logging</a></li>
  </ul></li>
</ul>
</div>
  <div role="note" aria-label="source link">
    <h3>本页</h3>
    <ul class="this-page-menu">
      <li><a href="../sources/topics/link-extractors.txt"
            rel="nofollow">显示源代码</a></li>
    </ul>
   </div>
<div id="searchbox" style="display: none" role="search">
  <h3>快速搜索</h3>
    <form class="search" action="../search.html" method="get">
      <div><input type="text" name="q" /></div>
      <div><input type="submit" value="转向" /></div>
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    
    <div class="footer">
      &copy;2008-2014, written by Scrapy developers, translated by Summer&Friends.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 1.4.6</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.9</a>
      
      |
      <a href="../sources/topics/link-extractors.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
    

  </body>
</html>