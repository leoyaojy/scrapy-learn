<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml" lang="zh_CN">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>通用爬虫(Broad Crawls) &#8212; Scrapy 0.24.1 文档</title>
    
    <link rel="stylesheet" href="../static/scrapydoc.css" type="text/css" />
    <link rel="stylesheet" href="../static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../',
        VERSION:     '0.24.1',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="../static/jquery.js"></script>
    <script type="text/javascript" src="../static/underscore.js"></script>
    <script type="text/javascript" src="../static/doctools.js"></script>
    <script type="text/javascript" src="../static/translations.js"></script>
    <link rel="top" title="Scrapy 0.24.1 文档" href="../index.html" />
    <link rel="next" title="借助Firefox来爬取" href="firefox.html" />
    <link rel="prev" title="实践经验(Common Practices)" href="practices.html" />
   
  <link rel="stylesheet" href="../static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head>
  <body role="document">
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
    
  <div class="section" id="broad-crawls">
<span id="topics-broad-crawls"></span><h1>通用爬虫(Broad Crawls)<a class="headerlink" href="#broad-crawls" title="永久链接至标题">¶</a></h1>
<p>Scrapy默认对特定爬取进行优化。这些站点一般被一个单独的Scrapy spider进行处理，
不过这并不是必须或要求的(例如，也有通用的爬虫能处理任何给定的站点)。</p>
<p>除了这种爬取完某个站点或没有更多请求就停止的&#8221;专注的爬虫&#8221;，还有一种通用的爬取类型，其能爬取大量(甚至是无限)的网站，
仅仅受限于时间或其他的限制。
这种爬虫叫做&#8221;通用爬虫(broad crawls)&#8221;，一般用于搜索引擎。</p>
<p>通用爬虫一般有以下通用特性:</p>
<ul class="simple">
<li>其爬取大量(一般来说是无限)的网站而不是特定的一些网站。</li>
<li>其不会将整个网站都爬取完毕，因为这十分不实际(或者说是不可能)完成的。相反，其会限制爬取的时间及数量。</li>
<li>其在逻辑上十分简单(相较于具有很多提取规则的复杂的spider)，数据会在另外的阶段进行后处理(post-processed)</li>
<li>其并行爬取大量网站以避免被某个网站的限制所限制爬取的速度(为表示尊重，每个站点爬取速度很慢但同时爬取很多站点)。</li>
</ul>
<p>正如上面所述，Scrapy默认设置是对特定爬虫做了优化，而不是通用爬虫。不过，
鉴于其使用了异步架构，Scrapy对通用爬虫也十分适用。
本篇文章总结了一些将Scrapy作为通用爬虫所需要的技巧，
以及相应针对通用爬虫的Scrapy设定的一些建议。</p>
<div class="section" id="id1">
<h2>增加并发<a class="headerlink" href="#id1" title="永久链接至标题">¶</a></h2>
<p>并发是指同时处理的request的数量。其有全局限制和局部(每个网站)的限制。</p>
<p>Scrapy默认的全局并发限制对同时爬取大量网站的情况并不适用，因此您需要增加这个值。
增加多少取决于您的爬虫能占用多少CPU。
一般开始可以设置为 <code class="docutils literal"><span class="pre">100</span></code> 。不过最好的方式是做一些测试，获得Scrapy进程占取CPU与并发数的关系。
为了优化性能，您应该选择一个能使CPU占用率在80%-90%的并发数。</p>
<p>增加全局并发数:</p>
<div class="highlight-default"><div class="highlight"><pre><span class="n">CONCURRENT_REQUESTS</span> <span class="o">=</span> <span class="mi">100</span>
</pre></div>
</div>
</div>
<div class="section" id="log">
<h2>降低log级别<a class="headerlink" href="#log" title="永久链接至标题">¶</a></h2>
<p>当进行通用爬取时，一般您所注意的仅仅是爬取的速率以及遇到的错误。
Scrapy使用 <code class="docutils literal"><span class="pre">INFO</span></code> log级别来报告这些信息。为了减少CPU使用率(及记录log存储的要求),
在生产环境中进行通用爬取时您不应该使用 <code class="docutils literal"><span class="pre">DEBUG</span></code> log级别。
不过在开发的时候使用 <code class="docutils literal"><span class="pre">DEBUG</span></code> 应该还能接受。</p>
<p>设置Log级别:</p>
<div class="highlight-default"><div class="highlight"><pre><span class="n">LOG_LEVEL</span> <span class="o">=</span> <span class="s1">&#39;INFO&#39;</span>
</pre></div>
</div>
</div>
<div class="section" id="cookies">
<h2>禁止cookies<a class="headerlink" href="#cookies" title="永久链接至标题">¶</a></h2>
<p>除非您 <em>真的</em> 需要，否则请禁止cookies。在进行通用爬取时cookies并不需要，
(搜索引擎则忽略cookies)。禁止cookies能减少CPU使用率及Scrapy爬虫在内存中记录的踪迹，提高性能。</p>
<p>禁止cookies:</p>
<div class="highlight-default"><div class="highlight"><pre><span class="n">COOKIES_ENABLED</span> <span class="o">=</span> <span class="kc">False</span>
</pre></div>
</div>
</div>
<div class="section" id="id2">
<h2>禁止重试<a class="headerlink" href="#id2" title="永久链接至标题">¶</a></h2>
<p>对失败的HTTP请求进行重试会减慢爬取的效率，尤其是当站点响应很慢(甚至失败)时，
访问这样的站点会造成超时并重试多次。这是不必要的，同时也占用了爬虫爬取其他站点的能力。</p>
<p>禁止重试:</p>
<div class="highlight-default"><div class="highlight"><pre><span class="n">RETRY_ENABLED</span> <span class="o">=</span> <span class="kc">False</span>
</pre></div>
</div>
</div>
<div class="section" id="id3">
<h2>减小下载超时<a class="headerlink" href="#id3" title="永久链接至标题">¶</a></h2>
<p>如果您对一个非常慢的连接进行爬取(一般对通用爬虫来说并不重要)，
减小下载超时能让卡住的连接能被快速的放弃并解放处理其他站点的能力。</p>
<p>减小下载超时:</p>
<div class="highlight-default"><div class="highlight"><pre><span class="n">DOWNLOAD_TIMEOUT</span> <span class="o">=</span> <span class="mi">15</span>
</pre></div>
</div>
</div>
<div class="section" id="id4">
<h2>禁止重定向<a class="headerlink" href="#id4" title="永久链接至标题">¶</a></h2>
<p>除非您对跟进重定向感兴趣，否则请考虑关闭重定向。
当进行通用爬取时，一般的做法是保存重定向的地址，并在之后的爬取进行解析。
这保证了每批爬取的request数目在一定的数量，
否则重定向循环可能会导致爬虫在某个站点耗费过多资源。</p>
<p>关闭重定向:</p>
<div class="highlight-default"><div class="highlight"><pre><span class="n">REDIRECT_ENABLED</span> <span class="o">=</span> <span class="kc">False</span>
</pre></div>
</div>
</div>
<div class="section" id="ajax-crawlable-pages">
<h2>启用 &#8220;Ajax Crawlable Pages&#8221; 爬取<a class="headerlink" href="#ajax-crawlable-pages" title="永久链接至标题">¶</a></h2>
<p>有些站点(基于2013年的经验数据，之多有1%)声明其为 <a class="reference external" href="https://developers.google.com/webmasters/ajax-crawling/docs/getting-started">ajax crawlable</a> 。
这意味着该网站提供了原本只有ajax获取到的数据的纯HTML版本。
网站通过两种方法声明:</p>
<ol class="arabic simple">
<li>在url中使用 <code class="docutils literal"><span class="pre">#!</span></code> - 这是默认的方式;</li>
<li>使用特殊的meta标签 - 这在&#8221;main&#8221;, &#8220;index&#8221; 页面中使用。</li>
</ol>
<p>Scrapy自动解决(1)；解决(2)您需要启用
<a class="reference internal" href="downloader-middleware.html#ajaxcrawl-middleware"><span class="std std-ref">AjaxCrawlMiddleware</span></a>:</p>
<div class="highlight-default"><div class="highlight"><pre><span class="n">AJAXCRAWL_ENABLED</span> <span class="o">=</span> <span class="kc">True</span>
</pre></div>
</div>
<p>通用爬取经常抓取大量的 &#8220;index&#8221; 页面；
AjaxCrawlMiddleware能帮助您正确地爬取。
由于有些性能问题，且对于特定爬虫没有什么意义，该中间默认关闭。</p>
</div>
</div>


    

          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
  <h3><a href="../index.html">內容目录</a></h3>
  <ul>
<li><a class="reference internal" href="#">通用爬虫(Broad Crawls)</a><ul>
<li><a class="reference internal" href="#id1">增加并发</a></li>
<li><a class="reference internal" href="#log">降低log级别</a></li>
<li><a class="reference internal" href="#cookies">禁止cookies</a></li>
<li><a class="reference internal" href="#id2">禁止重试</a></li>
<li><a class="reference internal" href="#id3">减小下载超时</a></li>
<li><a class="reference internal" href="#id4">禁止重定向</a></li>
<li><a class="reference internal" href="#ajax-crawlable-pages">启用 &#8220;Ajax Crawlable Pages&#8221; 爬取</a></li>
</ul>
</li>
</ul>
<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../index.html">Documentation overview</a><ul>
      <li>Previous: <a href="practices.html" title="上一章">实践经验(Common Practices)</a></li>
      <li>Next: <a href="firefox.html" title="下一章">借助Firefox来爬取</a></li>
  </ul></li>
</ul>
</div>
  <div role="note" aria-label="source link">
    <h3>本页</h3>
    <ul class="this-page-menu">
      <li><a href="../sources/topics/broad-crawls.txt"
            rel="nofollow">显示源代码</a></li>
    </ul>
   </div>
<div id="searchbox" style="display: none" role="search">
  <h3>快速搜索</h3>
    <form class="search" action="../search.html" method="get">
      <div><input type="text" name="q" /></div>
      <div><input type="submit" value="转向" /></div>
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    
    <div class="footer">
      &copy;2008-2014, written by Scrapy developers, translated by Summer&Friends.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 1.4.6</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.9</a>
      
      |
      <a href="../sources/topics/broad-crawls.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
    

  </body>
</html>